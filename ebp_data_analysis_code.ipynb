{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # RCSQ 6-Axis Sleep Study: Synthetic Datasets and Analysis\n",
    "#\n",
    "# This notebook:\n",
    "# - Uses a 6-axis Richards–Campbell Sleep Questionnaire (RCSQ)\n",
    "#   - Depth, Latency, Awakenings, Return, Quality, Noise\n",
    "# - Generates 4 synthetic datasets (each: 50 control + 50 intervention)\n",
    "#   1. randomized_data: fully random scores (0–100)\n",
    "#   2. no_effect_data: realistic sleep scores, no intervention effect\n",
    "#   3. small_effect_data: realistic sleep scores, small intervention effect\n",
    "#   4. large_effect_data: realistic sleep scores, large intervention effect\n",
    "# - Scores RCSQ total as the mean of the 6 axes (0–100)\n",
    "# - Computes Cronbach's alpha, t-tests, Mann–Whitney, and Cohen's d\n",
    "# - Displays a Markdown summary table of the results\n",
    "\n",
    "\n",
    "# %% \n",
    "# 1. Imports and configuration\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# For reproducibility\n",
    "RNG_SEED = 42\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use(\"default\")\n",
    "sns.set(context=\"notebook\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Define RCSQ structure and helper functions\n",
    "#\n",
    "# We treat RCSQ as 6 axes:\n",
    "# - Depth\n",
    "# - Latency\n",
    "# - Awakenings\n",
    "# - Return (return to sleep)\n",
    "# - Quality\n",
    "# - Noise (environmental noise)\n",
    "\n",
    "\n",
    "# %% \n",
    "# Column names for the 6-axis instrument\n",
    "RCSQ_COLS = [\n",
    "    \"rcsq_depth\",\n",
    "    \"rcsq_latency\",\n",
    "    \"rcsq_awakenings\",\n",
    "    \"rcsq_return\",\n",
    "    \"rcsq_quality\",\n",
    "    \"rcsq_noise\",\n",
    "]\n",
    "\n",
    "RCSQ_LABELS = {\n",
    "    \"rcsq_depth\": \"Depth\",\n",
    "    \"rcsq_latency\": \"Latency\",\n",
    "    \"rcsq_awakenings\": \"Awakenings\",\n",
    "    \"rcsq_return\": \"Return\",\n",
    "    \"rcsq_quality\": \"Quality\",\n",
    "    \"rcsq_noise\": \"Noise\",\n",
    "}\n",
    "\n",
    "\n",
    "def score_rcsq_total(df: pd.DataFrame, item_cols=RCSQ_COLS, out_col=\"rcsq_total\"):\n",
    "    \"\"\"\n",
    "    Score RCSQ total as the mean of available items (0–100) for each row.\n",
    "    \"\"\"\n",
    "    df[out_col] = df[item_cols].mean(axis=1, skipna=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def categorize_sleep(score: float, cutoff: float = 50.0) -> str:\n",
    "    \"\"\"\n",
    "    Categorize sleep based on RCSQ total score.\n",
    "    \"\"\"\n",
    "    if pd.isna(score):\n",
    "        return np.nan\n",
    "    return \"poor_sleep\" if score < cutoff else \"good_sleep\"\n",
    "\n",
    "\n",
    "def cronbach_alpha(df_items: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Compute Cronbach's alpha for a set of item columns.\n",
    "    \"\"\"\n",
    "    item_scores = df_items.dropna(axis=0)  # drop rows with missing items\n",
    "    k = item_scores.shape[1]\n",
    "    if k < 2:\n",
    "        return np.nan\n",
    "    variances = item_scores.var(axis=0, ddof=1)\n",
    "    total_var = item_scores.sum(axis=1).var(ddof=1)\n",
    "    if total_var == 0:\n",
    "        return np.nan\n",
    "    alpha = (k / (k - 1)) * (1 - variances.sum() / total_var)\n",
    "    return float(alpha)\n",
    "\n",
    "\n",
    "def cohen_d(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Cohen's d for independent samples x and y.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    if nx < 2 or ny < 2:\n",
    "        return np.nan\n",
    "    pooled_sd = np.sqrt(((nx - 1) * x.var(ddof=1) + (ny - 1) * y.var(ddof=1)) / (nx + ny - 2))\n",
    "    if pooled_sd == 0:\n",
    "        return np.nan\n",
    "    return float((x.mean() - y.mean()) / pooled_sd)\n",
    "\n",
    "\n",
    "def clip_0_100(array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Clip values to [0, 100] bounds (VAS scale).\n",
    "    \"\"\"\n",
    "    return np.clip(array, 0, 100)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Synthetic data generation\n",
    "#\n",
    "# We create 4 datasets, each with 100 subjects:\n",
    "# - 50 control\n",
    "# - 50 intervention\n",
    "#\n",
    "# We vary the *true* mean difference between groups:\n",
    "# - randomized_data: scores are uniform(0, 100) for all subjects, group labels assigned but not linked\n",
    "# - no_effect_data: realistic means, identical distribution in both groups\n",
    "# - small_effect_data: intervention mean slightly higher (small effect size)\n",
    "# - large_effect_data: intervention mean much higher (large effect size)\n",
    "\n",
    "\n",
    "# %% \n",
    "def generate_randomized_data(n_control=50, n_intervention=50) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fully random RCSQ data: each axis uniform(0, 100), independent of group.\n",
    "    Used to simulate a 'wild' dataset with no designed structure.\n",
    "    \"\"\"\n",
    "    n = n_control + n_intervention\n",
    "    patient_ids = np.arange(1, n + 1)\n",
    "\n",
    "    # Random group assignment but scores independent of group\n",
    "    groups = np.array([\"control\"] * n_control + [\"intervention\"] * n_intervention)\n",
    "    rng.shuffle(groups)\n",
    "\n",
    "    # Uniform random scores for each axis\n",
    "    scores = rng.uniform(0, 100, size=(n, len(RCSQ_COLS)))\n",
    "    scores = clip_0_100(scores)\n",
    "\n",
    "    df = pd.DataFrame(scores, columns=RCSQ_COLS)\n",
    "    df.insert(0, \"patient_id\", patient_ids)\n",
    "    df.insert(1, \"group\", groups)\n",
    "\n",
    "    score_rcsq_total(df)\n",
    "    df[\"sleep_category\"] = df[\"rcsq_total\"].apply(categorize_sleep)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_effect_data(\n",
    "    n_control=50,\n",
    "    n_intervention=50,\n",
    "    control_means=None,\n",
    "    intervention_means=None,\n",
    "    sds=None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate RCSQ data for control and intervention groups with specified means and SDs.\n",
    "    Means and SDs are length-6 vectors (for the 6 axes).\n",
    "    \"\"\"\n",
    "    if control_means is None:\n",
    "        control_means = np.array([60, 55, 50, 55, 60, 50], dtype=float)\n",
    "    if intervention_means is None:\n",
    "        intervention_means = np.array([60, 55, 50, 55, 60, 50], dtype=float)\n",
    "    if sds is None:\n",
    "        sds = np.array([15, 15, 15, 15, 15, 15], dtype=float)\n",
    "\n",
    "    # Control scores\n",
    "    control_scores = rng.normal(loc=control_means, scale=sds, size=(n_control, len(RCSQ_COLS)))\n",
    "    control_scores = clip_0_100(control_scores)\n",
    "\n",
    "    # Intervention scores\n",
    "    intervention_scores = rng.normal(\n",
    "        loc=intervention_means, scale=sds, size=(n_intervention, len(RCSQ_COLS))\n",
    "    )\n",
    "    intervention_scores = clip_0_100(intervention_scores)\n",
    "\n",
    "    # Assemble dataframe\n",
    "    df_control = pd.DataFrame(control_scores, columns=RCSQ_COLS)\n",
    "    df_control.insert(0, \"patient_id\", np.arange(1, n_control + 1))\n",
    "    df_control.insert(1, \"group\", \"control\")\n",
    "\n",
    "    df_intervention = pd.DataFrame(intervention_scores, columns=RCSQ_COLS)\n",
    "    df_intervention.insert(0, \"patient_id\", np.arange(n_control + 1, n_control + n_intervention + 1))\n",
    "    df_intervention.insert(1, \"group\", \"intervention\")\n",
    "\n",
    "    df = pd.concat([df_control, df_intervention], ignore_index=True)\n",
    "    score_rcsq_total(df)\n",
    "    df[\"sleep_category\"] = df[\"rcsq_total\"].apply(categorize_sleep)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Generate each dataset:\n",
    "\n",
    "# 1) Randomized data: fully random scores\n",
    "randomized_data = generate_randomized_data()\n",
    "\n",
    "# 2) No-effect data: same distribution in both groups (realistic sleep)\n",
    "base_means = np.array([60, 55, 50, 55, 60, 50], dtype=float)\n",
    "base_sds = np.array([12, 12, 12, 12, 12, 12], dtype=float)\n",
    "no_effect_data = generate_effect_data(\n",
    "    control_means=base_means,\n",
    "    intervention_means=base_means,\n",
    "    sds=base_sds,\n",
    ")\n",
    "\n",
    "# 3) Small effect: intervention slightly better (approx Cohen's d ~ 0.3–0.4)\n",
    "small_effect_control_means = np.array([60, 55, 50, 55, 60, 50], dtype=float)\n",
    "small_effect_intervention_means = np.array([66, 61, 56, 61, 66, 56], dtype=float)  # +6 points each axis\n",
    "small_effect_sds = np.array([12, 12, 12, 12, 12, 12], dtype=float)\n",
    "small_effect_data = generate_effect_data(\n",
    "    control_means=small_effect_control_means,\n",
    "    intervention_means=small_effect_intervention_means,\n",
    "    sds=small_effect_sds,\n",
    ")\n",
    "\n",
    "# 4) Large effect: intervention much better\n",
    "large_effect_control_means = np.array([55, 50, 45, 50, 55, 45], dtype=float)\n",
    "large_effect_intervention_means = np.array([80, 75, 70, 75, 80, 70], dtype=float)  # big effect\n",
    "large_effect_sds = np.array([12, 12, 12, 12, 12, 12], dtype=float)\n",
    "large_effect_data = generate_effect_data(\n",
    "    control_means=large_effect_control_means,\n",
    "    intervention_means=large_effect_intervention_means,\n",
    "    sds=large_effect_sds,\n",
    ")\n",
    "\n",
    "datasets = {\n",
    "    \"randomized_data\": randomized_data,\n",
    "    \"no_effect_data\": no_effect_data,\n",
    "    \"small_effect_data\": small_effect_data,\n",
    "    \"large_effect_data\": large_effect_data,\n",
    "}\n",
    "\n",
    "for name, d in datasets.items():\n",
    "    print(f\"{name}: shape = {d.shape}, mean RCSQ total = {d['rcsq_total'].mean():.2f}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Analysis helpers: group comparisons\n",
    "#\n",
    "# We'll define a function to:\n",
    "# - compute Cronbach's alpha for the 6 axes\n",
    "# - summarize means by group\n",
    "# - run Welch t-test and Mann–Whitney U test\n",
    "# - compute Cohen's d\n",
    "\n",
    "\n",
    "# %% \n",
    "def analyze_dataset(df: pd.DataFrame, name: str):\n",
    "    \"\"\"\n",
    "    Analyze a single RCSQ dataset:\n",
    "    - Cronbach's alpha\n",
    "    - group means\n",
    "    - Welch t-test\n",
    "    - Mann–Whitney U\n",
    "    - Cohen's d\n",
    "\n",
    "    Returns a summary dict with key statistics.\n",
    "    \"\"\"\n",
    "    # Reliability\n",
    "    alpha = cronbach_alpha(df[RCSQ_COLS])\n",
    "\n",
    "    # Groups\n",
    "    groups = df[\"group\"].unique()\n",
    "    if len(groups) != 2:\n",
    "        raise ValueError(f\"Dataset {name} does not have exactly 2 groups.\")\n",
    "\n",
    "    g1, g2 = sorted(groups)  # alphabetic order\n",
    "    scores_g1 = df.loc[df[\"group\"] == g1, \"rcsq_total\"].dropna().to_numpy()\n",
    "    scores_g2 = df.loc[df[\"group\"] == g2, \"rcsq_total\"].dropna().to_numpy()\n",
    "\n",
    "    mean_g1 = float(scores_g1.mean())\n",
    "    mean_g2 = float(scores_g2.mean())\n",
    "    diff = mean_g2 - mean_g1  # intervention - control if groups ordered that way\n",
    "\n",
    "    # Welch t-test\n",
    "    t_stat, p_t = stats.ttest_ind(scores_g1, scores_g2, equal_var=False)\n",
    "\n",
    "    # Mann–Whitney U\n",
    "    u_stat, p_u = stats.mannwhitneyu(scores_g1, scores_g2, alternative=\"two-sided\")\n",
    "\n",
    "    # Cohen's d (order g1, g2)\n",
    "    d = cohen_d(scores_g1, scores_g2)\n",
    "\n",
    "    summary = {\n",
    "        \"dataset\": name,\n",
    "        \"group_1\": g1,\n",
    "        \"group_2\": g2,\n",
    "        \"alpha\": alpha,\n",
    "        \"mean_group_1\": mean_g1,\n",
    "        \"mean_group_2\": mean_g2,\n",
    "        \"mean_diff_g2_minus_g1\": diff,\n",
    "        \"t_stat\": float(t_stat),\n",
    "        \"p_t\": float(p_t),\n",
    "        \"u_stat\": float(u_stat),\n",
    "        \"p_u\": float(p_u),\n",
    "        \"cohen_d_g2_minus_g1\": float(d),\n",
    "        \"n_group_1\": len(scores_g1),\n",
    "        \"n_group_2\": len(scores_g2),\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Run analysis on all datasets\n",
    "summaries = []\n",
    "for name, df in datasets.items():\n",
    "    s = analyze_dataset(df, name)\n",
    "    summaries.append(s)\n",
    "\n",
    "summary_df = pd.DataFrame(summaries)\n",
    "summary_df\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Quick visualization examples (optional)\n",
    "#\n",
    "# Some quick plots on the large-effect dataset to visually inspect the difference.\n",
    "\n",
    "\n",
    "# %%\n",
    "example_df = large_effect_data.copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for group_name, group_df in example_df.groupby(\"group\"):\n",
    "    sns.kdeplot(group_df[\"rcsq_total\"], ax=ax, label=group_name, fill=True, alpha=0.3)\n",
    "ax.set_title(\"RCSQ Total Distribution by Group (large_effect_data)\")\n",
    "ax.set_xlabel(\"RCSQ Total (0–100)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.boxplot(data=example_df, x=\"group\", y=\"rcsq_total\", ax=ax)\n",
    "ax.set_title(\"RCSQ Total by Group (large_effect_data)\")\n",
    "ax.set_xlabel(\"Group\")\n",
    "ax.set_ylabel(\"RCSQ Total (0–100)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Save synthetic datasets (optional)\n",
    "#\n",
    "# If you want to inspect the CSV files directly or use them in another notebook / program.\n",
    "\n",
    "\n",
    "# %%\n",
    "for name, df in datasets.items():\n",
    "    filename = f\"{name}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved: {filename}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Markdown summary of key statistics\n",
    "#\n",
    "# This cell builds a markdown table summarizing:\n",
    "# - Cronbach's alpha\n",
    "# - group means\n",
    "# - mean difference\n",
    "# - Cohen's d\n",
    "# - t-test p-value\n",
    "#\n",
    "# The output is rendered as Markdown in the notebook.\n",
    "\n",
    "\n",
    "# %%\n",
    "def make_markdown_summary_table(summary_df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Build a markdown table summarizing key results from summary_df.\n",
    "    \"\"\"\n",
    "    header = (\n",
    "        \"| Dataset | Group 1 | Group 2 | α (Cronbach) | Mean G1 | Mean G2 | Diff (G2−G1) | Cohen d (G2−G1) | p (Welch t) |\\n\"\n",
    "        \"|---------|---------|---------|--------------|---------|---------|--------------|-----------------|------------|\\n\"\n",
    "    )\n",
    "    rows = []\n",
    "    for _, row in summary_df.iterrows():\n",
    "        rows.append(\n",
    "            f\"| {row['dataset']} \"\n",
    "            f\"| {row['group_1']} \"\n",
    "            f\"| {row['group_2']} \"\n",
    "            f\"| {row['alpha']:.3f} \"\n",
    "            f\"| {row['mean_group_1']:.2f} \"\n",
    "            f\"| {row['mean_group_2']:.2f} \"\n",
    "            f\"| {row['mean_diff_g2_minus_g1']:.2f} \"\n",
    "            f\"| {row['cohen_d_g2_minus_g1']:.2f} \"\n",
    "            f\"| {row['p_t']:.4f} |\"\n",
    "        )\n",
    "    return header + \"\\n\".join(rows)\n",
    "\n",
    "\n",
    "md_table = make_markdown_summary_table(summary_df)\n",
    "display(Markdown(\"### Summary of 6-Axis RCSQ Synthetic Datasets\\n\\n\" + md_table))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
